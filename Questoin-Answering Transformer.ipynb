{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arl0bQjkPsk1",
        "outputId": "3ceb709c-e1d7-46fa-ae32-f37ecf4cb1b4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v3hlj7kPjW5",
        "outputId": "60f85e50-6169-4400-9f48-6d4e7594fdc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ask a question about Lord Ram (or press 'q' to quit'): Who are parents of lord rama?\n",
            "Answer: King Dasharatha and Queen Kausalya\n",
            "Ask a question about Lord Ram (or press 'q' to quit'): In which epic he was named?\n",
            "Answer: Ramayana\n",
            "Ask a question about Lord Ram (or press 'q' to quit'): For how long he went into exile?\n",
            "Answer: 14-year\n",
            "Ask a question about Lord Ram (or press 'q' to quit'): Which character embodies the characteristics  of lord Rama?\n",
            "Answer: Maryada Purushottama\n",
            "Ask a question about Lord Ram (or press 'q' to quit'): q\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Jan  7 23:55:10 2024\n",
        "\n",
        "@author: parth\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "### Use HuggingFace Transformers library\n",
        "\n",
        "\n",
        "\n",
        "# AutoModelForQuestionAnswering loads a pretrained model\n",
        "# AutoTokenizer loads pre-load tokenizer\n",
        "# Pipelines helps to access pre-trained models for NLP tasks\n",
        "\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
        "\n",
        "#Define pre-trained model roberta-base model, it is fine tuned on squad2 for question-answering\n",
        "model_name =  \"deepset/roberta-base-squad2\"\n",
        "\n",
        "#Load pre-trained question answering model\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "#Loads autotokenizer from pretarined model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "\n",
        "# Corrected Pipeline creation for question-answering\n",
        "nlp = pipeline(task='question-answering', model=model, tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "#Create a context\n",
        "\n",
        "context = \"\"\"\n",
        "            Sri Ram, also known as Lord Rama, is a revered deity in Hinduism and a central figure in the ancient Indian epic, the Ramayana. He is considered the seventh avatar of Lord Vishnu, one of the principal deities forming the holy trinity in Hinduism. Rama's life and journey symbolize the triumph of righteousness (dharma) over evil and adherence to moral values.\n",
        "\n",
        "            Born to King Dasharatha and Queen Kausalya in Ayodhya, Rama is portrayed as an epitome of virtue, exhibiting qualities of an ideal son, husband, and king. His life is marked by trials and tribulations, most notably his 14-year exile from Ayodhya, accompanied by his wife Sita and brother Lakshmana. The exile is a result of a promise made by his father to his stepmother, Kaikeyi, who wished for her son Bharata to become the king.\n",
        "\n",
        "            During his exile, Rama battles and defeats various demons, including the demon king Ravana, who abducts Sita. This leads to the epic war in Lanka, where Rama, assisted by an army of monkeys led by Hanuman, rescues Sita. Ramaâ€™s return to Ayodhya after his victory over Ravana is celebrated as Diwali, a major Hindu festival.\n",
        "\n",
        "            Lord Rama's character embodies the characteristics of an ideal person (Maryada Purushottama). He is revered for his unyielding adherence to dharma (duty/righteousness), despite facing personal trials. His reign in Ayodhya, known as Ram Rajya, is idealized as a period of perfect justice and moral harmony.\n",
        "\n",
        "            The narrative of Rama has had a profound impact on art, culture, and spirituality in India and across the Hindu diaspora. It has been subject to various interpretations and theatrical adaptations, reflecting its deep-seated influence in Indian culture and religion.\n",
        "\n",
        "            \"\"\"\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Ask a question about Lord Ram (or press 'q' to quit'): \")\n",
        "\n",
        "\n",
        "    if user_input.lower() == 'q':\n",
        "        break\n",
        "\n",
        "    QA_prompt = {\n",
        "        'question': user_input,\n",
        "        'context': context\n",
        "\n",
        "        }\n",
        "\n",
        "    result = nlp(QA_prompt)\n",
        "\n",
        "\n",
        "    print(f\"Answer: {result['answer']}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    }
  ]
}